{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "import random\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "from sklearn.utils import shuffle\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import product\n",
    "from sklearn.decomposition import PCA\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# EVALUATION modules\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "params = {'legend.fontsize': 20,\n",
    "          'figure.figsize': (9,6),\n",
    "         'axes.labelsize': 20,\n",
    "         'axes.titlesize':20,\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'axes.linewidth' : 2,\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(input_data, sequence_length, stride = 1, option = None):\n",
    "    \"\"\"\n",
    "     \n",
    "    \"\"\"\n",
    "    X = list()\n",
    "    \n",
    "    for i in range(0,len(input_data),stride):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + sequence_length\n",
    "        \n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(input_data):\n",
    "            break\n",
    "        \n",
    "        # gather input and output parts of the pattern\n",
    "        if option=='last':\n",
    "            seq_x = input_data[end_ix-1, :]\n",
    "        elif option=='next':\n",
    "            seq_x = input_data[end_ix, :]\n",
    "        else:\n",
    "            seq_x = input_data[i:end_ix, :]\n",
    "        X.append(seq_x)\n",
    "    \n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_signal(x_real,x_pred,var_names,num=1000,figsize=10):\n",
    "    input_dim = len(var_names)\n",
    "    cols = min(np.floor(input_dim**0.5).astype(int),4)\n",
    "    rows = (np.ceil(input_dim / cols)).astype(int)\n",
    "    gs   = gridspec.GridSpec(rows, cols)\n",
    "    fig  = plt.figure(figsize=(figsize, max(figsize, rows*2)))   \n",
    "    for i in range(input_dim):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        # ax.plot(np.arange(0,num),x_real[-num:,i],label=\"True\",marker='.',markeredgewidth=0.25, markersize=8)\n",
    "        # ax.plot(np.arange(0,num),x_pred[-num:,i],label=\"Pred\",marker='.',markeredgewidth=0.25, markersize=8)\n",
    "        ax.scatter(np.arange(0,num),x_real[-num:,i],label=\"True\",marker='.')\n",
    "        ax.scatter(np.arange(0,num),x_pred[-num:,i],label=\"Pred\",marker='.')\n",
    "        plt.title(var_names[i])\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sequence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generator(input_data, units, cycles, sequence_length=10,stride = 1, option=None):\n",
    "    \"\"\"\n",
    "     # Generates dataset with windows of sequence_length      \n",
    "    \"\"\"  \n",
    "    X = list()\n",
    "    unit_num=[]\n",
    "    c_num =[]\n",
    "    for i, elem_u in enumerate(list(np.unique(units))):\n",
    "        mask = np.ravel(units==elem_u)\n",
    "        c_mask = cycles[mask]\n",
    "        x_unit = input_data[mask]\n",
    "        for j in np.unique(c_mask):\n",
    "            mask = np.ravel(c_mask==j)\n",
    "            seq_x_u = split_sequences(x_unit[mask],sequence_length, stride, option)\n",
    "            X.append(seq_x_u)\n",
    "            unit_num.extend(np.ones(len(seq_x_u),dtype = int)*elem_u)\n",
    "            c_num.extend(np.ones(len(seq_x_u),dtype = int)*j)\n",
    "    \n",
    "    return np.vstack(X),np.array(unit_num).reshape(-1,1),np.array(c_num).reshape(-1,1)\n",
    "\n",
    "\n",
    "def sequence_generator_per_unit(input_data, units, cycles, sequence_length=10, stride =1,option=None):\n",
    "    \"\"\"\n",
    "     # Generates dataset with windows of sequence_length      \n",
    "    \"\"\"  \n",
    "    X = list()\n",
    "    unit_num=[]\n",
    "    c_num =[]\n",
    "    for i, elem_u in enumerate(list(np.unique(units))):\n",
    "        mask = np.ravel(units==elem_u)\n",
    "        x_unit = input_data[mask]\n",
    "        seq_x_u = split_sequences(x_unit,sequence_length, stride, option)\n",
    "        X.append(seq_x_u)\n",
    "        unit_num.extend(np.ones(len(seq_x_u),dtype = int)*elem_u)\n",
    "        c_num.append(split_sequences(cycles[mask],sequence_length, stride, option))\n",
    "    \n",
    "    return np.vstack(X),np.array(unit_num).reshape(-1,1),np.vstack(c_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight Class FC\n",
    "FC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XS_train (628969, 14)\n",
      "(628969, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data DEV\n",
    "with h5py.File(\"FC\"+str(FC)+\"/FC\"+str(FC)+'_dev'+\".h5\", 'r') as hdf:\n",
    "            # Development set\n",
    "            W_train = np.array(hdf.get('W_dev'), dtype='float16')             # W\n",
    "            X_s_train = np.array(hdf.get('X_s_dev'), dtype='float16')         # X_s\n",
    "            X_v_train = np.array(hdf.get('X_v_dev'), dtype='float16')         # X_v\n",
    "            T_train = np.array(hdf.get('T_dev'), dtype='float16')             # T\n",
    "            Y_train = np.array(hdf.get('Y_dev'), dtype='float16')             # RUL  \n",
    "            A_train = np.array(hdf.get('A_dev'), dtype='float16')\n",
    "            \n",
    "            # Varnams\n",
    "            W_var = np.array(hdf.get('W_var'))\n",
    "            X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "            X_v_var = np.array(hdf.get('X_v_var')) \n",
    "            T_var = np.array(hdf.get('T_var'))\n",
    "            A_var = np.array(hdf.get('A_var'))\n",
    "            \n",
    "                # from np.array to list dtype U4/U5\n",
    "            W_var = list(np.array(W_var, dtype='U20'))\n",
    "            X_s_var = list(np.array(X_s_var, dtype='U20'))  \n",
    "            X_v_var = list(np.array(X_v_var, dtype='U20')) \n",
    "            T_var = list(np.array(T_var, dtype='U20'))\n",
    "            A_var = list(np.array(A_var, dtype='U20'))\n",
    "            \n",
    "# Load data TEST\n",
    "mode = '_test'\n",
    "with h5py.File(\"FC\"+str(FC)+\"/FC\"+str(FC)+'_test'+\".h5\", 'r') as hdf:\n",
    "            # Development set\n",
    "            W_test = np.array(hdf.get('W_test'), dtype='float16')             # W\n",
    "            X_s_test = np.array(hdf.get('X_s_test'), dtype='float16')         # X_s\n",
    "            X_v_test = np.array(hdf.get('X_v_test'), dtype='float16')         # X_v\n",
    "            T_test = np.array(hdf.get('T_test'), dtype='float16')             # T\n",
    "            Y_test = np.array(hdf.get('Y_test'), dtype='float16')             # RUL  \n",
    "            A_test = np.array(hdf.get('A_test'), dtype='float16')\n",
    "\n",
    "units_train=A_train[:,0].reshape(-1,1)\n",
    "cycles_train=A_train[:,1].reshape(-1,1)\n",
    "fc_train = A_train[:,2].reshape(-1,1)\n",
    "hi_train = A_train[:,-1]\n",
    "\n",
    "units_test=A_test[:,0].reshape(-1,1)\n",
    "cycles_test=A_test[:,1].reshape(-1,1)\n",
    "fc_test = A_test[:,2].reshape(-1,1)\n",
    "hi_test = A_test[:,-1]\n",
    "\n",
    "print(\"XS_train\",X_s_train.shape)\n",
    "print(units_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxMin Scale $X_s$ and $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE\n",
    "# scaler_X = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_X = MinMaxScaler()\n",
    "X_s_train = scaler_X.fit_transform(X_s_train)\n",
    "X_s_test = scaler_X.transform(X_s_test)\n",
    "\n",
    "# scaler_W = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_W = MinMaxScaler()\n",
    "W_train = scaler_W.fit_transform(W_train)\n",
    "W_test = scaler_W.transform(W_test)\n",
    "\n",
    "scaler_Y = MinMaxScaler(feature_range=(0,1))\n",
    "Y_train = scaler_Y.fit_transform(Y_train)\n",
    "Y_test = scaler_Y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsamplig 0.1Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LEN = 50\n",
    "stride = 1\n",
    "\n",
    "#X_windows_test, U_windows_test,C_windows_test=sequence_generator(X_s_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "#W_windows_test,_,_=sequence_generator(W_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "#Y_windows_test,_,_=sequence_generator(Y_test,units_test,cycles_test,sequence_length=WINDOW_LEN,option='last',stride = stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 20.8 MiB for an array with shape (15591, 50, 14) and data type float16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19100\\3505035280.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_windows_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_windows_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC_windows_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_generator_per_unit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_s_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munits_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycles_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWINDOW_LEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mW_windows_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_generator_per_unit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munits_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycles_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWINDOW_LEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mY_windows_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_generator_per_unit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munits_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycles_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWINDOW_LEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'last'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19100\\3470710378.py\u001b[0m in \u001b[0;36msequence_generator_per_unit\u001b[1;34m(input_data, units, cycles, sequence_length, stride, option)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0melem_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mx_unit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mseq_x_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_unit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_x_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0munit_num\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_x_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0melem_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19100\\2618587921.py\u001b[0m in \u001b[0;36msplit_sequences\u001b[1;34m(input_data, sequence_length, stride, option)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 20.8 MiB for an array with shape (15591, 50, 14) and data type float16"
     ]
    }
   ],
   "source": [
    "X_windows_test, U_windows_test,C_windows_test=sequence_generator_per_unit(X_s_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "W_windows_test,_,_=sequence_generator_per_unit(W_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "Y_windows_test,_,_=sequence_generator_per_unit(Y_test,units_test,cycles_test,sequence_length=WINDOW_LEN,option='last',stride = stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed = 5\n",
    "seed=229\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"model.h5\")\n",
    "\n",
    "json_file = open(\"RUL_MODEL/FC\"+str(FC)+\"/\"+\"/model.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "rul_model = model_from_json(loaded_model_json)\n",
    "rul_model.load_weights(\"RUL_MODEL/FC\"+str(FC)+\"/\"+\"/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predicted = rul_model.predict((X_windows_test,W_windows_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predicted_ = scaler_Y.inverse_transform(rul_predicted)\n",
    "groud_truth = scaler_Y.inverse_transform(Y_windows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math \n",
    "mae=mean_absolute_error(rul_predicted_,groud_truth)\n",
    "mse=mean_squared_error(rul_predicted_,groud_truth)\n",
    "rmse=np.sqrt(mse)\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining Useful Life Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_U_test = DataFrame(data=U_windows_test, columns=['unit']) \n",
    "df_Y_test = DataFrame(data=Y_windows_test, columns=['RUL']) \n",
    "df_Y_hat_test = DataFrame(data=rul_predicted, columns=['RUL_hat'])\n",
    "df_test = pd.concat([df_U_test, df_Y_test,df_Y_hat_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.unique(units_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_windows_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
