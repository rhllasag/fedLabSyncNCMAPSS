{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "import random\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "from sklearn.utils import shuffle\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import product\n",
    "from sklearn.decomposition import PCA\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# EVALUATION modules\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "params = {'legend.fontsize': 20,\n",
    "          'figure.figsize': (9,6),\n",
    "         'axes.labelsize': 20,\n",
    "         'axes.titlesize':20,\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'axes.linewidth' : 2,\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type = 'GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "gpu=True\n",
    "if gpu == True:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      # Restrict TensorFlow to only use the first GPU\n",
    "      try:\n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "      except RuntimeError as e:\n",
    "            # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(input_data, sequence_length, stride = 1, option = None):\n",
    "    \"\"\"\n",
    "     \n",
    "    \"\"\"\n",
    "    X = list()\n",
    "    \n",
    "    for i in range(0,len(input_data),stride):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + sequence_length\n",
    "        \n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(input_data):\n",
    "            break\n",
    "        \n",
    "        # gather input and output parts of the pattern\n",
    "        if option=='last':\n",
    "            seq_x = input_data[end_ix-1, :]\n",
    "        elif option=='next':\n",
    "            seq_x = input_data[end_ix, :]\n",
    "        else:\n",
    "            seq_x = input_data[i:end_ix, :]\n",
    "        X.append(seq_x)\n",
    "    \n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_signal(x_real,x_pred,var_names,num=1000,figsize=10):\n",
    "    input_dim = len(var_names)\n",
    "    cols = min(np.floor(input_dim**0.5).astype(int),4)\n",
    "    rows = (np.ceil(input_dim / cols)).astype(int)\n",
    "    gs   = gridspec.GridSpec(rows, cols)\n",
    "    fig  = plt.figure(figsize=(figsize, max(figsize, rows*2)))   \n",
    "    for i in range(input_dim):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        # ax.plot(np.arange(0,num),x_real[-num:,i],label=\"True\",marker='.',markeredgewidth=0.25, markersize=8)\n",
    "        # ax.plot(np.arange(0,num),x_pred[-num:,i],label=\"Pred\",marker='.',markeredgewidth=0.25, markersize=8)\n",
    "        ax.scatter(np.arange(0,num),x_real[-num:,i],label=\"True\",marker='.')\n",
    "        ax.scatter(np.arange(0,num),x_pred[-num:,i],label=\"Pred\",marker='.')\n",
    "        plt.title(var_names[i])\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sequence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generator(input_data, units, cycles, sequence_length=10,stride = 1, option=None):\n",
    "    \"\"\"\n",
    "     # Generates dataset with windows of sequence_length      \n",
    "    \"\"\"  \n",
    "    X = list()\n",
    "    unit_num=[]\n",
    "    c_num =[]\n",
    "    for i, elem_u in enumerate(list(np.unique(units))):\n",
    "        mask = np.ravel(units==elem_u)\n",
    "        c_mask = cycles[mask]\n",
    "        x_unit = input_data[mask]\n",
    "        for j in np.unique(c_mask):\n",
    "            mask = np.ravel(c_mask==j)\n",
    "            seq_x_u = split_sequences(x_unit[mask],sequence_length, stride, option)\n",
    "            X.append(seq_x_u)\n",
    "            unit_num.extend(np.ones(len(seq_x_u),dtype = int)*elem_u)\n",
    "            c_num.extend(np.ones(len(seq_x_u),dtype = int)*j)\n",
    "    \n",
    "    return np.vstack(X),np.array(unit_num).reshape(-1,1),np.array(c_num).reshape(-1,1)\n",
    "\n",
    "\n",
    "def sequence_generator_per_unit(input_data, units, cycles, sequence_length=10, stride =1,option=None):\n",
    "    \"\"\"\n",
    "     # Generates dataset with windows of sequence_length      \n",
    "    \"\"\"  \n",
    "    X = list()\n",
    "    unit_num=[]\n",
    "    c_num =[]\n",
    "    for i, elem_u in enumerate(list(np.unique(units))):\n",
    "        mask = np.ravel(units==elem_u)\n",
    "        x_unit = input_data[mask]\n",
    "        seq_x_u = split_sequences(x_unit,sequence_length, stride, option)\n",
    "        X.append(seq_x_u)\n",
    "        unit_num.extend(np.ones(len(seq_x_u),dtype = int)*elem_u)\n",
    "        c_num.append(split_sequences(cycles[mask],sequence_length, stride, option))\n",
    "    \n",
    "    return np.vstack(X),np.array(unit_num).reshape(-1,1),np.vstack(c_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight Class FC\n",
    "FC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XS_train (628969, 14)\n",
      "(628969, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data DEV\n",
    "with h5py.File(\"FC\"+str(FC)+\"/FC\"+str(FC)+'_dev'+\".h5\", 'r') as hdf:\n",
    "            # Development set\n",
    "            W_train = np.array(hdf.get('W_dev'), dtype='float16')             # W\n",
    "            X_s_train = np.array(hdf.get('X_s_dev'), dtype='float16')         # X_s\n",
    "            X_v_train = np.array(hdf.get('X_v_dev'), dtype='float16')         # X_v\n",
    "            T_train = np.array(hdf.get('T_dev'), dtype='float16')             # T\n",
    "            Y_train = np.array(hdf.get('Y_dev'), dtype='float16')             # RUL  \n",
    "            A_train = np.array(hdf.get('A_dev'), dtype='float16')\n",
    "            \n",
    "            # Varnams\n",
    "            W_var = np.array(hdf.get('W_var'))\n",
    "            X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "            X_v_var = np.array(hdf.get('X_v_var')) \n",
    "            T_var = np.array(hdf.get('T_var'))\n",
    "            A_var = np.array(hdf.get('A_var'))\n",
    "            \n",
    "                # from np.array to list dtype U4/U5\n",
    "            W_var = list(np.array(W_var, dtype='U20'))\n",
    "            X_s_var = list(np.array(X_s_var, dtype='U20'))  \n",
    "            X_v_var = list(np.array(X_v_var, dtype='U20')) \n",
    "            T_var = list(np.array(T_var, dtype='U20'))\n",
    "            A_var = list(np.array(A_var, dtype='U20'))\n",
    "            \n",
    "# Load data TEST\n",
    "mode = '_test'\n",
    "with h5py.File(\"FC\"+str(FC)+\"/FC\"+str(FC)+'_test'+\".h5\", 'r') as hdf:\n",
    "            # Development set\n",
    "            W_test = np.array(hdf.get('W_test'), dtype='float16')             # W\n",
    "            X_s_test = np.array(hdf.get('X_s_test'), dtype='float16')         # X_s\n",
    "            X_v_test = np.array(hdf.get('X_v_test'), dtype='float16')         # X_v\n",
    "            T_test = np.array(hdf.get('T_test'), dtype='float16')             # T\n",
    "            Y_test = np.array(hdf.get('Y_test'), dtype='float16')             # RUL  \n",
    "            A_test = np.array(hdf.get('A_test'), dtype='float16')\n",
    "\n",
    "units_train=A_train[:,0].reshape(-1,1)\n",
    "cycles_train=A_train[:,1].reshape(-1,1)\n",
    "fc_train = A_train[:,2].reshape(-1,1)\n",
    "hi_train = A_train[:,-1]\n",
    "\n",
    "units_test=A_test[:,0].reshape(-1,1)\n",
    "cycles_test=A_test[:,1].reshape(-1,1)\n",
    "fc_test = A_test[:,2].reshape(-1,1)\n",
    "hi_test = A_test[:,-1]\n",
    "\n",
    "print(\"XS_train\",X_s_train.shape)\n",
    "print(units_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxMin Scale $X_s$ and $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE\n",
    "# scaler_X = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_X = MinMaxScaler()\n",
    "X_s_train = scaler_X.fit_transform(X_s_train)\n",
    "X_s_test = scaler_X.transform(X_s_test)\n",
    "\n",
    "# scaler_W = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_W = MinMaxScaler()\n",
    "W_train = scaler_W.fit_transform(W_train)\n",
    "W_test = scaler_W.transform(W_test)\n",
    "\n",
    "scaler_Y = MinMaxScaler(feature_range=(0,1))\n",
    "Y_train = scaler_Y.fit_transform(Y_train)\n",
    "Y_test = scaler_Y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsamplig 0.1Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LEN = 50\n",
    "stride = 1\n",
    "\n",
    "#X_windows_test, U_windows_test,C_windows_test=sequence_generator(X_s_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "#W_windows_test,_,_=sequence_generator(W_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "#Y_windows_test,_,_=sequence_generator(Y_test,units_test,cycles_test,sequence_length=WINDOW_LEN,option='last',stride = stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_windows_test, U_windows_test,C_windows_test=sequence_generator_per_unit(X_s_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "W_windows_test,_,_=sequence_generator_per_unit(W_test,units_test,cycles_test,sequence_length=WINDOW_LEN,stride = stride)\n",
    "Y_windows_test,_,_=sequence_generator_per_unit(Y_test,units_test,cycles_test,sequence_length=WINDOW_LEN,option='last',stride = stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed = 5\n",
    "seed=229\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"model.h5\")\n",
    "\n",
    "json_file = open(\"RUL_MODEL/FC\"+str(FC)+\"/\"+\"/model.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "rul_model = model_from_json(loaded_model_json)\n",
    "rul_model.load_weights(\"RUL_MODEL/FC\"+str(FC)+\"/\"+\"/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 19:38:23.558478: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.38GiB (rounded to 1480136192)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-12-05 19:38:23.558512: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-12-05 19:38:23.558526: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 22, Chunks in use: 20. 5.5KiB allocated for chunks. 5.0KiB in use in bin. 1.6KiB client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558535: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558544: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558552: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558559: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558567: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558574: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558581: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558592: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 156.5KiB allocated for chunks. 156.5KiB in use in bin. 90.0KiB client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558601: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 270.2KiB allocated for chunks. 270.2KiB in use in bin. 160.0KiB client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558610: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 625.0KiB allocated for chunks. 625.0KiB in use in bin. 625.0KiB client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558617: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558624: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558632: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558639: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558646: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558653: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558661: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558668: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558676: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 145.28MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558686: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-05 19:38:23.558694: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 1.38GiB was 256.00MiB, Chunk State: \n",
      "2023-12-05 19:38:23.558701: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 153419776\n",
      "2023-12-05 19:38:23.558710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000000 of size 1280 next 1\n",
      "2023-12-05 19:38:23.558716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000500 of size 256 next 2\n",
      "2023-12-05 19:38:23.558723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000600 of size 256 next 3\n",
      "2023-12-05 19:38:23.558729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000700 of size 256 next 5\n",
      "2023-12-05 19:38:23.558735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000800 of size 256 next 6\n",
      "2023-12-05 19:38:23.558741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000900 of size 256 next 4\n",
      "2023-12-05 19:38:23.558747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000a00 of size 256 next 7\n",
      "2023-12-05 19:38:23.558753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a000b00 of size 137984 next 9\n",
      "2023-12-05 19:38:23.558760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022600 of size 256 next 11\n",
      "2023-12-05 19:38:23.558766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022700 of size 256 next 10\n",
      "2023-12-05 19:38:23.558771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022800 of size 256 next 12\n",
      "2023-12-05 19:38:23.558777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022900 of size 256 next 17\n",
      "2023-12-05 19:38:23.558783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022a00 of size 256 next 15\n",
      "2023-12-05 19:38:23.558789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022b00 of size 256 next 16\n",
      "2023-12-05 19:38:23.558795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022c00 of size 256 next 21\n",
      "2023-12-05 19:38:23.558800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022d00 of size 256 next 20\n",
      "2023-12-05 19:38:23.558806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022e00 of size 256 next 22\n",
      "2023-12-05 19:38:23.558812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a022f00 of size 256 next 23\n",
      "2023-12-05 19:38:23.558818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a023000 of size 79616 next 13\n",
      "2023-12-05 19:38:23.558825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a036700 of size 320000 next 14\n",
      "2023-12-05 19:38:23.558831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a084900 of size 138752 next 25\n",
      "2023-12-05 19:38:23.558837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a0a6700 of size 256 next 18\n",
      "2023-12-05 19:38:23.558843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a0a6800 of size 256 next 28\n",
      "2023-12-05 19:38:23.558849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f094a0a6900 of size 256 next 8\n",
      "2023-12-05 19:38:23.558855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a0a6a00 of size 256 next 24\n",
      "2023-12-05 19:38:23.558861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a0a6b00 of size 256 next 31\n",
      "2023-12-05 19:38:23.558867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f094a0a6c00 of size 256 next 32\n",
      "2023-"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/zhaw-raul/fedLabSyncNCMAPSS/Plots per Flight Class.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bthanos.mlwin.ch/home/zhaw-raul/fedLabSyncNCMAPSS/Plots%20per%20Flight%20Class.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m rul_predicted \u001b[39m=\u001b[39m rul_model\u001b[39m.\u001b[39;49mpredict((X_windows_test,W_windows_test))\n",
      "File \u001b[0;32m~/anaconda3/envs/fedLabSync/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/fedLabSync/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12-05 19:38:23.558873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a0a6d00 of size 80640 next 26\n",
      "2023-12-05 19:38:23.558879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f094a0ba800 of size 320000 next 27\n",
      "2023-12-05 19:38:23.558887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f094a108a00 of size 152335872 next 18446744073709551615\n",
      "2023-12-05 19:38:23.558892: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-12-05 19:38:23.558900: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 20 Chunks of size 256 totalling 5.0KiB\n",
      "2023-12-05 19:38:23.558907: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-12-05 19:38:23.558915: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 79616 totalling 77.8KiB\n",
      "2023-12-05 19:38:23.558921: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 80640 totalling 78.8KiB\n",
      "2023-12-05 19:38:23.558928: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 137984 totalling 134.8KiB\n",
      "2023-12-05 19:38:23.558935: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 138752 totalling 135.5KiB\n",
      "2023-12-05 19:38:23.558942: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 320000 totalling 625.0KiB\n",
      "2023-12-05 19:38:23.558949: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 1.03MiB\n",
      "2023-12-05 19:38:23.558956: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 153419776 memory_limit_: 153419776 available bytes: 0 curr_region_allocation_bytes_: 306839552\n",
      "2023-12-05 19:38:23.558966: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       153419776\n",
      "InUse:                         1083392\n",
      "MaxInUse:                      1631744\n",
      "NumAllocs:                          83\n",
      "MaxAllocSize:                   320000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-12-05 19:38:23.558974: W tensorflow/tsl/framework/bfc_allocator.cc:497] *___________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rul_predicted = rul_model.predict((X_windows_test,W_windows_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predicted_ = scaler_Y.inverse_transform(rul_predicted)\n",
    "groud_truth = scaler_Y.inverse_transform(Y_windows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math \n",
    "mae=mean_absolute_error(rul_predicted_,groud_truth)\n",
    "mse=mean_squared_error(rul_predicted_,groud_truth)\n",
    "rmse=np.sqrt(mse)\n",
    "\n",
    "print(\"MAE:\",mae)\n",
    "print(\"MSE:\",mse)\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining Useful Life Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_U_test = DataFrame(data=U_windows_test, columns=['unit']) \n",
    "df_Y_test = DataFrame(data=Y_windows_test, columns=['RUL']) \n",
    "df_Y_hat_test = DataFrame(data=rul_predicted, columns=['RUL_hat'])\n",
    "df_test = pd.concat([df_U_test, df_Y_test,df_Y_hat_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.unique(units_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_windows_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
